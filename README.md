# insurance_services_optimization_through_machine_learning

La compaÃ±Ã­a de seguros Sure Tomorrow quiere resolver varias tareas con la ayuda de machine learning y te pide que evalÃºes esa posibilidad.

# DescripciÃ³n

La compaÃ±Ã­a de seguros Sure Tomorrow quiere resolver varias tareas con la ayuda de machine learning y te pide que evalÃºes esa posibilidad.

- Tarea 1: encontrar clientes que sean similares a un cliente determinado. Esto ayudarÃ¡ a los agentes de la compaÃ±Ã­a con el marketing.
- Tarea 2: predecir la probabilidad de que un nuevo cliente reciba una prestaciÃ³n del seguro. Â¿Puede un modelo de predictivo funcionar mejor que un modelo dummy?
- Tarea 3: predecir el nÃºmero de prestaciones de seguro que un nuevo cliente pueda recibir utilizando un modelo de regresiÃ³n lineal.
- Tarea 4: proteger los datos personales de los clientes sin afectar al modelo del ejercicio anterior. Es necesario desarrollar un algoritmo de transformaciÃ³n de datos que dificulte la recuperaciÃ³n de la informaciÃ³n personal si los datos caen en manos equivocadas. Esto se denomina enmascaramiento u ofuscaciÃ³n de datos. Pero los datos deben protegerse de tal manera que no se vea afectada la calidad de los modelos de machine learning. No es necesario elegir el mejor modelo, basta con demostrar que el algoritmo funciona correctamente.

# Tarea 1. Clientes similares

En el lenguaje de ML, es necesario desarrollar un procedimiento que devuelva los k vecinos mÃ¡s cercanos (objetos) para un objeto dado basÃ¡ndose en la distancia entre los objetos. Es posible que quieras revisar las siguientes lecciones (capÃ­tulo -> lecciÃ³n)- Distancia entre vectores -> Distancia euclidiana

Distancia entre vectores -> Distancia Manhattan
Para resolver la tarea, podemos probar diferentes mÃ©tricas de distancia.

Escribe una funciÃ³n que devuelva los k vecinos mÃ¡s cercanos para un ğ‘›ğ‘¡â„
objeto basÃ¡ndose en una mÃ©trica de distancia especificada. A la hora de realizar esta tarea no debe tenerse en cuenta el nÃºmero de prestaciones de seguro recibidas. Puedes utilizar una implementaciÃ³n ya existente del algoritmo kNN de scikit-learn (consulta el enlace) o tu propia implementaciÃ³n. PruÃ©balo para cuatro combinaciones de dos casos- Escalado

los datos no estÃ¡n escalados
los datos se escalan con el escalador MaxAbsScaler
MÃ©tricas de distancia
Euclidiana
Manhattan
Responde a estas preguntas:- Â¿El hecho de que los datos no estÃ©n escalados afecta al algoritmo kNN? Si es asÃ­, Â¿cÃ³mo se manifiesta?- Â¿QuÃ© tan similares son los resultados al utilizar la mÃ©trica de distancia Manhattan (independientemente del escalado)?

Respuestas a las preguntas

Â¿El hecho de que los datos no estÃ©n escalados afecta al algoritmo kNN? Si es asÃ­, Â¿cÃ³mo se manifiesta?

SÃ­, el hecho de que los datos no estÃ©n escalados puede afectar al algoritmo kNN. Esto se manifiesta en cÃ³mo se calcula la distancia entre los puntos. Cuando las caracterÃ­sticas no estÃ¡n en la misma escala, aquellas con valores mÃ¡s grandes dominarÃ¡n la contribuciÃ³n a la distancia total. Esto puede llevar a que las distancias se vean distorsionadas y que las caracterÃ­sticas con valores mÃ¡s grandes tengan un impacto desproporcionado en la clasificaciÃ³n de los vecinos mÃ¡s cercanos.

Â¿QuÃ© tan similares son los resultados al utilizar la mÃ©trica de distancia Manhattan (independientemente del escalado)?

Los resultados al utilizar la mÃ©trica de distancia Manhattan tienden a ser similares independientemente del escalado de los datos. Esto se debe a que la distancia Manhattan calcula la distancia entre dos puntos sumando las diferencias absolutas entre las coordenadas de cada punto. A diferencia de la distancia euclidiana, que considera la longitud del vector entre dos puntos, la distancia Manhattan se enfoca en la distancia horizontal y vertical entre los puntos en un espacio bidimensional.

Tarea 2. Â¿Es probable que el cliente reciba una prestaciÃ³n del seguro?
En tÃ©rminos de machine learning podemos considerarlo como una tarea de clasificaciÃ³n binaria.

Con el valor de insurance_benefits superior a cero como objetivo, evalÃºa si el enfoque de clasificaciÃ³n kNN puede funcionar mejor que el modelo dummy. Instrucciones:

Construye un clasificador basado en KNN y mide su calidad con la mÃ©trica F1 para k=1...10 tanto para los datos originales como para los escalados. SerÃ­a interesante observar cÃ³mo k puede influir en la mÃ©trica de evaluaciÃ³n y si el escalado de los datos provoca alguna diferencia. Puedes utilizar una implementaciÃ³n ya existente del algoritmo de clasificaciÃ³n kNN de scikit-learn (consulta el enlace) o tu propia implementaciÃ³n.- Construye un modelo dummy que, en este caso, es simplemente un modelo aleatorio. DeberÃ­a devolver "1" con cierta probabilidad. Probemos el modelo con cuatro valores de probabilidad: 0, la probabilidad de pagar cualquier prestaciÃ³n del seguro, 0.5, 1. La probabilidad de pagar cualquier prestaciÃ³n del seguro puede definirse como:

ğ‘ƒ{prestaciÃ³n de seguro recibida}=(nÃºmero de clientes que han recibido alguna prestaciÃ³n de seguronÃºmero) / (total de clientes)

Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporciÃ³n 70:30.

Â¿Es probable que el cliente reciba una prestaciÃ³n del seguro?

El anÃ¡lisis de la probabilidad de recibir una prestaciÃ³n del seguro se realizÃ³ utilizando un modelo dummy aleatorio con diferentes probabilidades (0, probabilidad real de recibir una prestaciÃ³n del seguro, 0.5 y 1). Los resultados muestran que el F1-score varÃ­a dependiendo de la probabilidad utilizada en el modelo dummy, lo que sugiere que la probabilidad de recibir una prestaciÃ³n del seguro influye en la capacidad del modelo para predecir correctamente dichas prestaciones.

Â¿El enfoque de clasificaciÃ³n kNN puede funcionar mejor que el modelo dummy?

Para responder a esta pregunta, se construyÃ³ y evaluÃ³ un clasificador kNN con diferentes valores de k (1 a 10). La evaluaciÃ³n se realizÃ³ utilizando la mÃ©trica F1-score. Comparando los resultados del clasificador kNN con los del modelo dummy, podemos determinar si el enfoque de clasificaciÃ³n kNN es mÃ¡s efectivo para predecir la recepciÃ³n de prestaciones del seguro en comparaciÃ³n con el modelo dummy.

Tarea 3. RegresiÃ³n (con regresiÃ³n lineal)
Con insurance_benefits como objetivo, evalÃºa cuÃ¡l serÃ­a la RECM de un modelo de regresiÃ³n lineal.

Construye tu propia implementaciÃ³n de regresiÃ³n lineal. Para ello, recuerda cÃ³mo estÃ¡ formulada la soluciÃ³n de la tarea de regresiÃ³n lineal en tÃ©rminos de LA. Comprueba la RECM tanto para los datos originales como para los escalados. Â¿Puedes ver alguna diferencia en la RECM con respecto a estos dos casos?

Denotemos- ğ‘‹
: matriz de caracterÃ­sticas; cada fila es un caso, cada columna es una caracterÃ­stica, la primera columna estÃ¡ formada por unidades- ğ‘¦
â€” objetivo (un vector)- ğ‘¦Ì‚
â€” objetivo estimado (un vector)- ğ‘¤
â€” vector de pesos La tarea de regresiÃ³n lineal en el lenguaje de las matrices puede formularse asÃ­:
ğ‘¦=ğ‘‹ğ‘¤
El objetivo de entrenamiento es entonces encontrar esa ğ‘¤
w que minimice la distancia L2 (ECM) entre ğ‘‹ğ‘¤
y ğ‘¦
:

minğ‘¤ğ‘‘2(ğ‘‹ğ‘¤,ğ‘¦)orminğ‘¤MSE(ğ‘‹ğ‘¤,ğ‘¦)
Parece que hay una soluciÃ³n analÃ­tica para lo anteriormente expuesto:
ğ‘¤=(ğ‘‹ğ‘‡ğ‘‹)âˆ’1ğ‘‹ğ‘‡ğ‘¦
La fÃ³rmula anterior puede servir para encontrar los pesos ğ‘¤
y estos Ãºltimos pueden utilizarse para calcular los valores predichos
ğ‘¦Ì‚ =ğ‘‹ğ‘£ğ‘ğ‘™ğ‘¤
Divide todos los datos correspondientes a las etapas de entrenamiento/prueba respetando la proporciÃ³n 70:30. Utiliza la mÃ©trica RECM para evaluar el modelo.

Observaciones

BasÃ¡ndonos en los resultados obtenidos, observamos que el modelo de regresiÃ³n lineal ajustado a los datos originales muestra un RMSE (Error CuadrÃ¡tico Medio) mÃ¡s bajo de aproximadamente 0.34, lo que indica una mayor precisiÃ³n en las predicciones en comparaciÃ³n con el modelo ajustado a los datos escalados, que tiene un RMSE de aproximadamente 0.74. Aunque el R2 (Coeficiente de DeterminaciÃ³n) se mantiene constante en ambos casos alrededor de 0.66, sugiriendo una consistencia en la capacidad explicativa del modelo, la diferencia en el RMSE sugiere que la informaciÃ³n de la escala original de las caracterÃ­sticas es importante para las predicciones mÃ¡s precisas en este contexto de predicciÃ³n de beneficios del seguro.

Tarea 4. Ofuscar datos
Lo mejor es ofuscar los datos multiplicando las caracterÃ­sticas numÃ©ricas (recuerda que se pueden ver como la matriz ğ‘‹
) por una matriz invertible ğ‘ƒ
.

ğ‘‹â€²=ğ‘‹Ã—ğ‘ƒ
Trata de hacerlo y comprueba cÃ³mo quedarÃ¡n los valores de las caracterÃ­sticas despuÃ©s de la transformaciÃ³n. Por cierto, la propiedad de invertibilidad es importante aquÃ­, asÃ­ que asegÃºrate de que ğ‘ƒ
sea realmente invertible.

Puedes revisar la lecciÃ³n 'Matrices y operaciones matriciales -> MultiplicaciÃ³n de matrices' para recordar la regla de multiplicaciÃ³n de matrices y su implementaciÃ³n con NumPy.

Â¿Puedes adivinar la edad o los ingresos de los clientes despuÃ©s de la transformaciÃ³n?

DespuÃ©s de la transformaciÃ³n, no es posible adivinar con precisiÃ³n la edad o los ingresos de los clientes simplemente observando los datos ofuscados resultantes de la multiplicaciÃ³n de la matriz X por la matriz invertible P. Los valores transformados son muy diferentes de los datos originales y no conservan una relaciÃ³n directa con las caracterÃ­sticas originales, lo que dificulta la interpretaciÃ³n y la predicciÃ³n de las edades o los ingresos de los clientes.

Â¿Puedes recuperar los datos originales de ğ‘‹â€²
si conoces ğ‘ƒ
? Intenta comprobarlo a travÃ©s de los cÃ¡lculos moviendo ğ‘ƒ
del lado derecho de la fÃ³rmula anterior al izquierdo. En este caso las reglas de la multiplicaciÃ³n matricial son realmente Ãºtiles

Seguramente puedes ver que algunos valores no son exactamente iguales a los de los datos originales. Â¿CuÃ¡l podrÃ­a ser la razÃ³n de ello?

La razÃ³n por la que algunos valores no son exactamente iguales a los datos originales despuÃ©s de la recuperaciÃ³n puede deberse a errores de redondeo y precisiÃ³n numÃ©rica durante el proceso de cÃ¡lculo. Aunque se utilizÃ³ la matriz invertible ğ‘ƒ para ofuscar los datos y luego se intentÃ³ recuperar los datos originales multiplicando por la inversa de ğ‘ƒ, la precisiÃ³n numÃ©rica limitada en las operaciones matriciales y de punto flotante puede llevar a pequeÃ±as discrepancias entre los valores recuperados y los valores originales.

4 Prueba de que la ofuscaciÃ³n de datos puede funcionar con regresiÃ³n lineal
En este proyecto la tarea de regresiÃ³n se ha resuelto con la regresiÃ³n lineal. Tu siguiente tarea es demostrar analytically que el mÃ©todo de ofuscaciÃ³n no afectarÃ¡ a la regresiÃ³n lineal en tÃ©rminos de valores predichos, es decir, que sus valores seguirÃ¡n siendo los mismos. Â¿Lo puedes creer? Pues no hace falta que lo creas, Â¡tienes que que demostrarlo!

Entonces, los datos estÃ¡n ofuscados y ahora tenemos ğ‘‹Ã—ğ‘ƒ
en lugar de tener solo ğ‘‹
. En consecuencia, hay otros pesos ğ‘¤ğ‘ƒ
como
ğ‘¤=(ğ‘‹ğ‘‡ğ‘‹)âˆ’1ğ‘‹ğ‘‡ğ‘¦â‡’ğ‘¤ğ‘ƒ=[(ğ‘‹ğ‘ƒ)ğ‘‡ğ‘‹ğ‘ƒ]âˆ’1(ğ‘‹ğ‘ƒ)ğ‘‡ğ‘¦
Â¿CÃ³mo se relacionarÃ­an ğ‘¤
y ğ‘¤ğ‘ƒ
si simplificÃ¡ramos la fÃ³rmula de ğ‘¤ğ‘ƒ
anterior?

Â¿CuÃ¡les serÃ­an los valores predichos con ğ‘¤ğ‘ƒ
?

Â¿QuÃ© significa esto para la calidad de la regresiÃ³n lineal si esta se mide mediante la RECM? Revisa el ApÃ©ndice B Propiedades de las matrices al final del cuaderno. Â¡AllÃ­ encontrarÃ¡s fÃ³rmulas muy Ãºtiles!

No es necesario escribir cÃ³digo en esta secciÃ³n, basta con una explicaciÃ³n analÃ­tica.

Respuesta

elaciÃ³n entre ğ‘¤
y ğ‘¤ğ‘ƒ
: La fÃ³rmula de los pesos de la regresiÃ³n lineal con los datos ofuscados ğ‘¤ğ‘ƒ
se puede expresar como: ğ‘¤ğ‘ƒ=[(ğ‘‹ğ‘ƒ)ğ‘‡ğ‘‹ğ‘ƒ]âˆ’1(ğ‘‹ğ‘ƒ)ğ‘‡ğ‘¦
. Si simplificamos esta expresiÃ³n, notaremos que ğ‘‹ğ‘‡ğ‘‹
se puede representar como ğ‘‹ğ‘‡ğ‘‹=(ğ‘‹ğ‘ƒ)ğ‘‡(ğ‘‹ğ‘ƒ)
, ya que ğ‘‹ğ‘ƒ
es simplemente la matriz de datos original ğ‘‹
multiplicada por la matriz de ofuscaciÃ³n ğ‘ƒ
. Por lo tanto, podemos escribir: ğ‘¤ğ‘ƒ=[ğ‘‹ğ‘‡ğ‘‹]âˆ’1(ğ‘‹ğ‘ƒ)ğ‘‡ğ‘¦
. Si comparamos esta expresiÃ³n con la fÃ³rmula original de los pesos de la regresiÃ³n lineal (ğ‘¤
), vemos que son idÃ©nticas, lo que significa que los pesos obtenidos despuÃ©s de la ofuscaciÃ³n son los mismos que los de la regresiÃ³n lineal original. Esto demuestra que la ofuscaciÃ³n de los datos no afecta la estimaciÃ³n de los pesos en la regresiÃ³n lineal.

Valores predichos con ğ‘¤ğ‘ƒ
: Los valores predichos con los datos ofuscados (ğ‘‹Ã—ğ‘ƒ
) utilizando los pesos ğ‘¤ğ‘ƒ
se pueden calcular de la misma manera que con los datos originales. Dado un nuevo conjunto de caracterÃ­sticas ğ‘‹â€², los valores predichos ğ‘¦Ì‚
se calculan como ğ‘‹â€²ğ‘¤ğ‘ƒ
, donde ğ‘¤ğ‘ƒ
es el vector de pesos obtenidos despuÃ©s de la ofuscaciÃ³n.

Implicaciones para la calidad de la regresiÃ³n lineal: Dado que los pesos de la regresiÃ³n lineal no se ven afectados por la ofuscaciÃ³n de datos y los valores predichos se calculan de manera similar, la calidad de la regresiÃ³n lineal medida por el RMSE no se verÃ¡ afectada por la ofuscaciÃ³n. El RMSE seguirÃ¡ siendo una medida vÃ¡lida de la precisiÃ³n del modelo, independientemente de si los datos estÃ¡n ofuscados o no. Esto significa que la capacidad predictiva del modelo de regresiÃ³n lineal se mantiene incluso despuÃ©s de la ofuscaciÃ³n de datos.

Prueba analÃ­tica

Nuestra prueba analÃ­tica respalda la conclusiÃ³n de que la ofuscaciÃ³n de datos puede funcionar con regresiÃ³n lineal sin afectar la precisiÃ³n del modelo ni la evaluaciÃ³n de su calidad mediante el RMSE

5 Prueba de regresiÃ³n lineal con ofuscaciÃ³n de datos
Ahora, probemos que la regresiÃ³n lineal pueda funcionar, en tÃ©rminos computacionales, con la transformaciÃ³n de ofuscaciÃ³n elegida. Construye un procedimiento o una clase que ejecute la regresiÃ³n lineal opcionalmente con la ofuscaciÃ³n. Puedes usar una implementaciÃ³n de regresiÃ³n lineal de scikit-learn o tu propia implementaciÃ³n. Ejecuta la regresiÃ³n lineal para los datos originales y los ofuscados, compara los valores predichos y los valores de las mÃ©tricas RMSE y ğ‘…2
. Â¿Hay alguna diferencia?

Procedimiento

Crea una matriz cuadrada ğ‘ƒ
de nÃºmeros aleatorios.- Comprueba que sea invertible. Si no lo es, repite el primer paso hasta obtener una matriz invertible.- <Â¡ tu comentario aquÃ­ !>
Utiliza ğ‘‹ğ‘ƒ
como la nueva matriz de caracterÃ­sticas

Observaciones

Los resultados muestran una diferencia muy pequeÃ±a en el RMSE entre los datos originales y los ofuscados, con valores prÃ¡cticamente cero en ambos casos. AdemÃ¡s, el coeficiente de determinaciÃ³n ğ‘…2
es igual a 1 en ambos conjuntos de datos, lo que sugiere que el modelo se ajusta perfectamente a los datos de entrenamiento y explica toda la variabilidad presente. Sin embargo, es importante tener en cuenta que al obtener un RMSE de 0 y un ğ‘…2
de 1, existe la posibilidad de sobreajuste del modelo, especialmente dado que se estÃ¡ prediciendo sobre los mismos datos utilizados para entrenarlo.

Conclusiones
En resumen, el proyecto destaca la relevancia de varias etapas clave en el anÃ¡lisis de datos y el aprendizaje automÃ¡tico. En primer lugar, el preprocesamiento cuidadoso de los datos es fundamental para garantizar la calidad y la coherencia de los conjuntos de datos utilizados. AdemÃ¡s, la selecciÃ³n adecuada de modelos de aprendizaje automÃ¡tico y tÃ©cnicas de ingenierÃ­a de caracterÃ­sticas puede marcar una gran diferencia en el rendimiento y la precisiÃ³n de los resultados obtenidos. TambiÃ©n se encontrÃ³ que la escala de los datos puede influir significativamente en el desempeÃ±o de los algoritmos, destacando la importancia de este paso en el proceso. Por Ãºltimo, se demostrÃ³ que la ofuscaciÃ³n de datos es una medida efectiva para salvaguardar la privacidad y la seguridad de la informaciÃ³n sensible, lo que subraya la necesidad de considerar la protecciÃ³n de datos en proyectos de anÃ¡lisis de datos.

Lista de control
Escribe 'x' para verificar. Luego presiona Shift+Enter.

Jupyter Notebook estÃ¡ abierto
El cÃ³digo no tiene errores- [ ] Las celdas estÃ¡n ordenadas de acuerdo con la lÃ³gica y el orden de ejecuciÃ³n
Se ha realizado la tarea 1
EstÃ¡ presente el procedimiento que puede devolver k clientes similares para un cliente determinado
Se probÃ³ el procedimiento para las cuatro combinaciones propuestas - [ ] Se respondieron las preguntas sobre la escala/distancia- [ ] Se ha realizado la tarea 2
Se construyÃ³ y probÃ³ el modelo de clasificaciÃ³n aleatoria para todos los niveles de probabilidad - [ ] Se construyÃ³ y probÃ³ el modelo de clasificaciÃ³n kNN tanto para los datos originales como para los escalados. Se calculÃ³ la mÃ©trica F1.- [ ] Se ha realizado la tarea 3
Se implementÃ³ la soluciÃ³n de regresiÃ³n lineal mediante operaciones matriciales - [ ] Se calculÃ³ la RECM para la soluciÃ³n implementada- [ ] Se ha realizado la tarea 4
Se ofuscaron los datos mediante una matriz aleatoria e invertible P - [ ] Se recuperaron los datos ofuscados y se han mostrado algunos ejemplos - [ ] Se proporcionÃ³ la prueba analÃ­tica de que la transformaciÃ³n no afecta a la RECM - [ ] Se proporcionÃ³ la prueba computacional de que la transformaciÃ³n no afecta a la RECM- [ ] Se han sacado conclusiones
ApÃ©ndices
6 ApÃ©ndice A: Escribir fÃ³rmulas en los cuadernos de Jupyter
Puedes escribir fÃ³rmulas en tu Jupyter Notebook utilizando un lenguaje de marcado proporcionado por un sistema de publicaciÃ³n de alta calidad llamado ğ¿ğ´ğ‘‡ğ¸ğ‘‹
(se pronuncia como "Lah-tech"). Las fÃ³rmulas se verÃ¡n como las de los libros de texto.

Para incorporar una fÃ³rmula a un texto, pon el signo de dÃ³lar ($) antes y despuÃ©s del texto de la fÃ³rmula, por ejemplo: 12Ã—32=34
or ğ‘¦=ğ‘¥2,ğ‘¥â‰¥1
.

Si una fÃ³rmula debe estar en el mismo pÃ¡rrafo, pon el doble signo de dÃ³lar ($$) antes y despuÃ©s del texto de la fÃ³rmula, por ejemplo:
ğ‘¥Â¯=1ğ‘›âˆ‘ğ‘–=1ğ‘›ğ‘¥ğ‘–.
El lenguaje de marcado de LaTeX es muy popular entre las personas que utilizan fÃ³rmulas en sus artÃ­culos, libros y textos. Puede resultar complicado, pero sus fundamentos son sencillos. Consulta esta ficha de ayuda (materiales en inglÃ©s) de dos pÃ¡ginas para aprender a componer las fÃ³rmulas mÃ¡s comunes.

7 ApÃ©ndice B: Propiedades de las matrices
Las matrices tienen muchas propiedades en cuanto al Ã¡lgebra lineal. AquÃ­ se enumeran algunas de ellas que pueden ayudarte a la hora de realizar la prueba analÃ­tica de este proyecto.

Distributividad ğ´(ğµ+ğ¶)=ğ´ğµ+ğ´ğ¶
No conmutatividad ğ´ğµâ‰ ğµğ´
Propiedad asociativa de la multiplicaciÃ³n (ğ´ğµ)ğ¶=ğ´(ğµğ¶)
Propiedad de identidad multiplicativa ğ¼ğ´=ğ´ğ¼=ğ´
ğ´âˆ’1ğ´=ğ´ğ´âˆ’1=ğ¼
(ğ´ğµ)âˆ’1=ğµâˆ’1ğ´âˆ’1
Reversibilidad de la transposiciÃ³n de un producto de matrices, (ğ´ğµ)ğ‘‡=ğµğ‘‡ğ´ğ‘‡
